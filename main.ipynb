{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import threading\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_curve, auc, f1_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the train dataset and start to explore about it <br>\n",
    "train data have labels and test data do not have\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = 'train.csv'\n",
    "train_df = pd.read_csv(train_file_path)\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing values in my data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature explanation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**id**\t Unique ID for the customer <br>\n",
    "**Gender**\t Gender of the customer <br>\n",
    "**Age**\t Age of the customer <br>\n",
    "**Driving_License**\t 0 : Customer does not have DL, 1 : Customer already has DL <br>\n",
    "**Region_Code**\t Unique code for the region of the customer <br>\n",
    "**Previously_Insured**\t 1 : Customer already has Vehicle Insurance, 0 : Customer doesn't have Vehicle Insurance <br>\n",
    "**Vehicle_Age**\t Age of the Vehicle <br>\n",
    "**Vehicle_Damage**\t 1 : Customer got his/her vehicle damaged in the past. 0 : Customer didn't get his/her vehicle damaged in the past. <br>\n",
    "**Annual_Premium**\t The amount customer needs to pay as premium in the year <br>\n",
    "**Policy_Sales_Channel**\tAnonymized Code for the channel of outreaching to the customer ie. Different Agents, Over Mail, Over Phone, In Person, etc. <br>\n",
    "**Vintage**\t Number of Days, Customer has been associated with the company <br>\n",
    "**Response**\t1 : Customer is interested, 0 : Customer is not interested <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_feature_dist(df, feature):    \n",
    "    plt.figure(figsize=(4,4))\n",
    "    value_counts = df[feature].value_counts()\n",
    "    plt.bar(value_counts.index, value_counts.values, color=['mediumturquoise', 'orchid'])\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Distribution')\n",
    "    plt.show()\n",
    "\n",
    "show_feature_dist(train_df, 'Gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Vehicle_Age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vehicle_age_pie_chart(df):    \n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.pie(df['Vehicle_Age'].value_counts(),labels=train_df['Vehicle_Age'].value_counts().index, autopct='%1.1f%%', colors=['#66b3ff', '#99ff99', '#ffcc99'])\n",
    "    plt.show()\n",
    "\n",
    "vehicle_age_pie_chart(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Vehicle_Damage'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Driving_License'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the categorical feature to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_feature_to_binary(df, mapping_key, value:str):\n",
    "    # Check if the column already contains 0 or 1 before mapping\n",
    "    if not set(df[value]).issubset({0, 1}):\n",
    "        df[value] = df[value].map(mapping_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_mapping = {'Female': 1, 'Male': 0}\n",
    "convert_feature_to_binary(train_df, gender_mapping, 'Gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vehicle_mapping = {'Yes': 1, 'No': 0}\n",
    "convert_feature_to_binary(train_df, Vehicle_mapping, 'Vehicle_Damage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle with the categoric feature Vehicle_Age <br>\n",
    "i need to encode the categorical feature so it will be possible to work with them in the model part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categoric_feature(df, feature)-> pd.DataFrame:\n",
    "    encoder = OneHotEncoder(sparse=False, drop='first') # i drop the first va,ue of the categorical to avoid multicollinearity\n",
    "    df_encoded_array = encoder.fit_transform(df[[feature]])\n",
    "\n",
    "    # Create a DataFrame from the encoded array\n",
    "    df_encoded = pd.DataFrame(df_encoded_array, columns=encoder.get_feature_names_out([feature]))\n",
    "    df_encoded = df_encoded.astype(int)\n",
    "    column_list = df_encoded.columns\n",
    "    # Check if columns of train_df_encoded are in train_df\n",
    "    if column_list[0] not in df.columns:\n",
    "        new_df = pd.concat([df, df_encoded], axis=1)\n",
    "        new_df = new_df.drop(feature, axis=1)\n",
    "    return new_df\n",
    "\n",
    "new_df = encode_categoric_feature(train_df, 'Vehicle_Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "id column is a column with unique values designed to identify the observations, but it has no role in my data visualization or processing the data so i am going to drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_column = new_df['id']\n",
    "my_df = new_df.drop('id', axis=1)\n",
    "my_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corelation Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "sns.heatmap(data=my_df.corr(method=\"pearson\", numeric_only=True), vmin=-1, vmax=1, annot=True, cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that there is strong negative correlation between the feature vehicle damage in the past and the feature previously insured.<br> multiple reasons might cause to that , for example maybe the company does not want to insure a person who damaged his car(it may indicate that the person does not drive carefully), or maybe the insurance price is more expensive because his car was damaged so it's not worth for him to insure the vehicle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_dist(df):    \n",
    "    fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(15, 15))\n",
    "    axes = axes.flatten()\n",
    "    for i, col in enumerate(df.columns):\n",
    "        #add kde curve to the histogram, providing a more continuous and smooth representation of the data distribution\n",
    "        sns.histplot(df[col], kde=True, ax=axes[i])\n",
    "        axes[i].set_title(f\"Distribution of {col} Data\")\n",
    "    # tight_layout ensure that subplots fit within the figure area without overlapping or crowding    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "feature_dist(my_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_feature = ['Age', 'Region_Code', 'Annual_Premium', 'Policy_Sales_Channel', 'Vintage']\n",
    "def display_box_plot(df,feature_list):\n",
    "    for feature in feature_list:\n",
    "        fig = px.box(df,y=feature, title=f\"Distrubution of {feature}\")\n",
    "        fig.update_layout(height=500, width=500)\n",
    "        fig.show()\n",
    "\n",
    "display_box_plot(my_df,numeric_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the box plot of annual premium there are outliers values.<br>\n",
    "Also the feature does not seems with normal distribution so i need to considering standardize them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* split the data to train and test, so i could evaluate my model performance in future \n",
    "* standardize my data, makes the features on the same scale\n",
    "* handle with outliers \n",
    "* reduce dimension - not must, i should consider it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = my_df.copy()\n",
    "y = df_copy['Response']\n",
    "X = df_copy.drop('Response', axis=1)\n",
    "X_train, X_test ,y_train, y_test= train_test_split(X, y, test_size = 0.20, random_state = 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"X train set shape: {X_train.shape}, y train set shape: {y_train.shape}\")\n",
    "print(f\"X test set shape: {X_test.shape}, y test set shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardizing the data <br>\n",
    "It is important to standards the data before using algorithms that rely on distances between data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_the_df(train_df, df_to_scale):    \n",
    "    all_row_labels = df_to_scale.index.tolist()\n",
    "    all_column_labels = df_to_scale.columns.tolist()\n",
    "    \n",
    "    scaler = RobustScaler()\n",
    "    scaler.fit(train_df)\n",
    "    scaled_array = scaler.transform(df_to_scale)\n",
    "    # Convert NumPy array to Pandas DataFrame with labels\n",
    "    data_frame = pd.DataFrame(scaled_array, index = all_row_labels, columns = all_column_labels)\n",
    "    return data_frame\n",
    "\n",
    "X_train_scaled = scale_the_df(train_df=X_train, df_to_scale=X_train)\n",
    "X_test_scaled = scale_the_df(train_df=X_train, df_to_scale=X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RobustScaler method should handle also with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the box-plot for numeric features again <br>\n",
    "first i will combine the train and test scaled data and then make all the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df = pd.concat([X_train_scaled,X_test_scaled], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_box_plot(scaled_df,numeric_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use grid search to find the best parameters for the 3 models that i chose\n",
    "* Evaluate the model using K-fold cross validation, f1 score\n",
    "* Display ROC curve every model and its AUC score\n",
    "* Show the confusion matrix of the best model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Grid Search method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter grids for each model\n",
    "svm_param_grid = {'C': [0.01, 0.1, 1]}\n",
    "knn_param_grid = {'n_neighbors': [3, 5, 7, 9, 11]}\n",
    "random_forest_param_grid = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10, 15],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "svm_classifier = SVC()\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "rf_classifier = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About SVM model: <br>\n",
    "Small C: A larger margin but more misclassifications are allowed.<br>\n",
    "Large C: A smaller margin but fewer misclassifications are allowed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform grid search using Thread pool method to efficient the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "cv_param = 3\n",
    "\n",
    "df = pd.concat([X_test_scaled, y_train],axis=0)\n",
    "subset_fraction = 0.1\n",
    "# Create a random subset of the data so the grid search will be faster\n",
    "subset_df = df.sample(frac=subset_fraction, random_state=42)\n",
    "print(subset_df)\n",
    "subset_y = subset_df.iloc[:, -1]\n",
    "print(subset_y)\n",
    "subset_x = subset_df.iloc[:, :-1]\n",
    "print(subset_x)\n",
    "\n",
    "def use_grid_search(model, grid_params: dict, X, y):\n",
    "    model_to_grid = GridSearchCV(model, grid_params, cv=cv_param, scoring='accuracy', n_jobs=-1)\n",
    "    model_to_grid.fit(X, y)\n",
    "    return model_to_grid\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "    futures = [executor.submit(use_grid_search, svm_classifier, svm_param_grid, subset_x, subset_y),\n",
    "    executor.submit(use_grid_search, knn_classifier, knn_param_grid, subset_x, subset_y),\n",
    "    executor.submit(use_grid_search,rf_classifier, random_forest_param_grid, subset_x, subset_y)]\n",
    "\n",
    "    \n",
    "svm_grid = futures[0].result()\n",
    "knn_grid = futures[1].result()\n",
    "random_forest_grid = futures[2].result()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_grid = use_grid_search(svm_classifier, svm_param_grid, X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_grid = use_grid_search(knn_classifier, knn_param_grid, X_train_scaled, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random_forest_grid = use_grid_search(rf_classifier, random_forest_param_grid, X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Get the best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_svm_model = svm_grid.best_estimator_\n",
    "print(\"Logistic Regression - Best Hyperparameter:\", svm_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_knn_model = knn_grid.best_estimator_\n",
    "print(\"\\nK-Nearest Neighbors - Best Hyperparameter:\", knn_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random_forest_model = random_forest_grid.best_estimator_\n",
    "print(\"\\nRandom Forest - Best Hyperparameter:\", random_forest_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving the result for future because the grid search took for long time:<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold cross validation evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_model_evaluation(X, y, models_list, k_fold=5):    \n",
    "    for model in models_list:\n",
    "        scores = cross_val_score(model, X, y, cv=k_fold, scoring='accuracy')\n",
    "        # Display the average performance score\n",
    "        print(f\"Average Accuracy of {model}:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = pd.concat([y_train, y_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = [best_svm_model, best_knn_model, best_random_forest_model]\n",
    "cross_val_model_evaluation(scaled_df, y_df, models_list, k_fold=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the models use f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_one_score_evaluate_models(X_test, y_test, models_list):\n",
    "    for model in models_list:\n",
    "        y_pred = model.predict(X_test)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        print(f\"f1 score for {model} is {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_one_score_evaluate_models(X_test_scaled, y_test, models_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display ROC curve of the models and AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(models):\n",
    "    for model in models:\n",
    "        y_probability = model.predict_proba(X_test_scaled)\n",
    "        fpr, tpr , thresholds = roc_curve(y_test , y_probability[ : , 1])\n",
    "        plt.figure(figsize=(5,5))\n",
    "        plt.plot(fpr, tpr, color='darkorange', label='ROC')\n",
    "        plt.plot([0,1],[0,1], color='navy', linestyle='--')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        print('AUC:%.2f'%auc(fpr, tpr))\n",
    "\n",
    "plot_roc_curve(models_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
